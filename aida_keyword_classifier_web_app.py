# -*- coding: utf-8 -*-
"""AIDA Keyword Classifier Web App

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W7gIW86CsVSdmgRC2xhFHy1bsgkw8klS
"""

import streamlit as st
import pandas as pd
from io import BytesIO
import json
import requests
import time
from typing import Dict, Any, List

# --- Constants and Initialization ---
# NOTE: The actual API key is provided at runtime by the environment.
API_KEY = ""
MODEL_NAME = "gemini-2.5-flash-preview-05-20"
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={API_KEY}"
MAX_RETRIES = 5

# Attempt to load rules from aida_data.json.
# We'll use a fixed path here assuming it's accessible.
def load_aida_rules() -> Dict[str, List[str]]:
    """Loads AIDA rules from the aida_data.json file."""
    try:
        # Check if the file name is available in the environment to reference
        rules_filename = 'aida_data.json'

        # NOTE: In a real environment, you might need a more specific path
        # but for this context, we assume it's in the same directory.
        with open(rules_filename, 'r') as f:
            rules = json.load(f)
            # Ensure keys are capitalized for consistent internal use
            return {k.capitalize(): [str(item).lower() for item in v] for k, v in rules.items()}
    except FileNotFoundError:
        st.error(f"Configuration file '{rules_filename}' not found. Please ensure it exists.")
        return {}
    except json.JSONDecodeError as e:
        st.error(f"Error decoding JSON in '{rules_filename}'. Please check syntax (commas, quotes, brackets). Details: {e}")
        return {}
    except Exception as e:
        st.error(f"An unexpected error occurred loading rules: {e}")
        return {}

# Load the rules only once when the app starts
RULES = load_aida_rules()

# --- AIDA Classification Logic ---

def classify_keyword(keyword: str, rules: Dict[str, List[str]]) -> str:
    """
    Classifies a keyword based on simple rule-based matching using loaded rules.
    """
    if not rules:
        return "Rules Missing"

    keyword_lower = keyword.lower()
    for stage, words in rules.items():
        # Check if any rule word is present in the keyword
        if any(word in keyword_lower for word in words):
            return stage
    return "Unclassified"

@st.cache_data(show_spinner="Analyzing keyword with AI...")
def __aida_stage_classification(keyword: str, rules: Dict[str, List[str]]) -> str:
    """
    Uses the Gemini API to classify a keyword into an AIDA stage,
    allowing it to use general knowledge outside the explicit rules.
    """
    if not rules:
        return "Rules Missing"

    system_prompt = (
        "You are an expert digital marketing analyst specializing in the AIDA funnel "
        "(Attention/Awareness, Interest, Desire, Action). Your task is to classify a given user "
        "search keyword into the SINGLE best AIDA stage. "
        "Respond ONLY with the single word for the stage (Attention, Interest, Desire, or Action). "
        "If none of the stages fit, respond with 'Unclassified'."
    )

    # Use the loaded rules for context in the AI prompt
    rule_list_str = "\n".join([f"- {stage}: {', '.join(words)}" for stage, words in rules.items()])

    user_query = (
        f"Classify the following keyword into one of the AIDA stages (Attention, Interest, Desire, Action, or Unclassified). "
        f"You may use the following examples as a guide, but use your best judgment for complex queries:\n"
        f"--- AIDA Keyword Examples ---\n{rule_list_str}\n"
        f"--- Keyword to Classify ---\n'{keyword}'"
    )

    payload = {
        "contents": [{ "parts": [{ "text": user_query }] }],
        "systemInstruction": { "parts": [{ "text": system_prompt }] },
    }

    # Simple exponential backoff retry loop
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(API_URL, headers={'Content-Type': 'application/json'}, data=json.dumps(payload))
            response.raise_for_status() # Raise exception for bad status codes (4xx or 5xx)

            result = response.json()
            candidate = result.get('candidates', [{}])[0]
            stage_text = candidate.get('content', {}).get('parts', [{}])[0].get('text', 'Unclassified').strip()

            # Clean and validate the response
            # Check for the possible stage names (Attention/Awareness are often used interchangeably)
            valid_stages = ["Attention", "Awareness", "Interest", "Desire", "Action"]
            if stage_text in valid_stages:
                # Standardize the output (e.g., convert "Awareness" to "Attention" if needed)
                return stage_text if stage_text != "Awareness" else "Attention"

            return "Unclassified"

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                # Wait before retrying (exponential backoff)
                sleep_time = 2 ** attempt
                time.sleep(sleep_time)
            else:
                print(f"Final API Error: {e}")
                return "API Error"
        except Exception as e:
            print(f"An unexpected error occurred during API processing: {e}")
            return "Error"

    return "API Error"


def process_dataframe(df: pd.DataFrame, rules: Dict[str, List[str]], column_name: str) -> pd.DataFrame:
    """Processes DataFrame for bulk classification using the rule-based approach."""
    df[column_name] = df[column_name].astype(str).fillna('')
    df['AIDA Stage (Rule-Based)'] = df[column_name].apply(lambda x: classify_keyword(x, rules))
    return df

def process_dataframe_ai(df: pd.DataFrame, rules: Dict[str, List[str]], column_name: str) -> pd.DataFrame:
    """Processes DataFrame for bulk classification using the AI approach."""
    df[column_name] = df[column_name].astype(str).fillna('')
    df['AIDA Stage (AI-Powered)'] = df[column_name].apply(lambda x: __aida_stage_classification(x, rules))
    return df

# --- Helper function for download button ---
@st.cache_data
def convert_df_to_excel(df):
    """Converts a DataFrame to an Excel file buffer for download."""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='AIDA_Classification')
    processed_data = output.getvalue()
    return processed_data

# --- Configuration and Initialization ---
st.set_page_config(layout="wide", page_title="AIDA Keyword Classifier")

# --- Main App Title and Description ---
st.title("üöÄ AI-Powered AIDA Keyword Classification Tool")
st.markdown("Use this tool to categorize your marketing keywords into the Attention, Interest, Desire, or Action stages of the AIDA funnel. Choose between fast **Rule-Based** matching or intelligent **AI-Powered** classification.")

# --- Sidebar for Rules Display and Customization ---
st.sidebar.header("Classification Rules (Rule-Based)")
if RULES:
    st.sidebar.markdown(
        """
        The **Rule-Based** classifier checks for these specific words.
        The **AI-Powered** classifier uses these as hints but relies on general AI knowledge.
        """
    )
    # Display the loaded rules
    for stage, words in RULES.items():
        st.sidebar.subheader(f"‚ú® {stage}")
        st.sidebar.text(", ".join(words))
else:
    st.sidebar.error("Rules could not be loaded. Check 'aida_data.json'.")


# --- Tabs for Input Methods ---
tab_manual, tab_bulk = st.tabs(["‚úçÔ∏è Single Keyword Entry", "üìÅ Bulk File Upload (Excel/CSV)"])


# 1. MANUAL ENTRY TAB
with tab_manual:
    st.header("Single Keyword Analysis")

    col1, col2 = st.columns([3, 1])

    with col1:
        user_keyword = st.text_input(
            "Enter your keyword or phrase here:",
            placeholder="e.g., best affordable laptop for students"
        )

    with col2:
        classification_method = st.radio(
            "Select Classification Method:",
            ["AI-Powered", "Rule-Based"],
            index=0,
            help="AI-Powered uses the Gemini API for smart classification. Rule-Based uses only the sidebar keyword list."
        )

    if st.button("Classify Keyword", type="primary") and user_keyword:
        if classification_method == "Rule-Based":
            stage = classify_keyword(user_keyword, RULES)
            method_note = "Rule-Based"
        else:
            stage = __aida_stage_classification(user_keyword, RULES)
            method_note = "AI-Powered"

        # Display the result with styling
        if stage in ["Unclassified", "API Error", "Error", "Rules Missing"]:
            st.warning(f"Keyword: **'{user_keyword}'** was **{stage}** via **{method_note}** classification.", icon="‚ö†Ô∏è")
        else:
            st.success(f"Keyword: **'{user_keyword}'** is in the **{stage}** stage via **{method_note}** classification.", icon="‚úÖ")

        if method_note == "Rule-Based":
            st.info("The Rule-Based classification is based on simple keyword matching. If the result is incorrect, adjust the rules shown in the sidebar.")
        else:
             st.info("The AI-Powered classification uses Gemini's advanced understanding of marketing intent. Results are generally superior to rule-based methods.")


# 2. BULK UPLOAD TAB
with tab_bulk:
    st.header("Bulk Keyword Analysis")

    uploaded_file = st.file_uploader(
        "Upload an Excel (.xlsx) or CSV file.",
        type=["xlsx", "csv"],
        help="The file must contain a column named 'Keyword' (or the name you specify below)."
    )

    col_name_input, method_select = st.columns(2)

    with col_name_input:
        # Input field for the column name, useful if it's not 'Keyword'
        keyword_col_name = st.text_input(
            "Enter the exact name of the keyword column in your file:",
            value="Keyword"
        )

    with method_select:
        bulk_classification_method = st.radio(
            "Select Bulk Classification Method:",
            ["Rule-Based", "AI-Powered"], # Swapped order, defaulting to Rule-Based for bulk speed
            index=0,
            help="Rule-Based is extremely fast but relies only on the sidebar keyword list. AI-Powered uses the Gemini API, which is slower but more accurate."
        )

    if uploaded_file is not None:
        try:
            # Read the file based on type
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else: # Must be Excel (.xlsx)
                df = pd.read_excel(uploaded_file, engine='openpyxl')

            # Show a preview of the original data
            st.subheader("Original Data Preview")
            st.dataframe(df.head())

            # Check if the required column exists before processing
            if keyword_col_name not in df.columns:
                st.error(f"Error: The uploaded file does not contain a column named **'{keyword_col_name}'**.")
            else:
                if bulk_classification_method == "Rule-Based":
                     # Process the DataFrame using the rule-based approach
                    processed_df = process_dataframe(df, RULES, keyword_col_name)
                    st.success("Rule-Based classification complete.")
                else:
                    # Process the DataFrame using the AI approach
                    # NOTE: Be cautious with large files, as AI processing can take time.
                    processed_df = process_dataframe_ai(df, RULES, keyword_col_name)
                    st.success("AI-Powered classification complete.")

                st.subheader("Classification Results")
                # Move original keyword column to the front of the results display
                cols = [keyword_col_name] + [col for col in processed_df.columns if col != keyword_col_name]
                st.dataframe(processed_df[cols], use_container_width=True)

                # Generate Download Button
                st.download_button(
                    label="‚¨áÔ∏è Download Classified Excel File",
                    data=convert_df_to_excel(processed_df),
                    file_name="AIDA_Classified_Keywords.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )

        except ImportError:
            st.error("Missing dependency! Please run `pip install openpyxl` in your terminal to enable Excel file uploads.")
        except Exception as e:
            st.error(f"An error occurred during file processing. Please ensure the file format is correct and the column name is accurate. Check your terminal for full error details.")
            print(f"File Processing Error: {e}")
            st.exception(e)